# ğŸ¤– CyFutureAI â€” L1 Automation Chatbot & Voicebot for Customer Care

<p align="center">
  <img src="https://img.shields.io/badge/GenAI-Automation-blue?style=for-the-badge">
  <img src="https://img.shields.io/badge/LangChain-v3.0-blueviolet?style=for-the-badge">
  <img src="https://img.shields.io/badge/LLM-Azure%20OpenAI-brightgreen?style=for-the-badge">
  <img src="https://img.shields.io/badge/Sentiment-Analysis-orange?style=for-the-badge">
</p>

ğŸš€ **CyFutureAI** is a fully functional, end-to-end intelligent chatbot & voicebot system designed to automate Level-1 customer support. It combines the power of **LangChain**, **LLMs (Azure OpenAI GPT-4o)**, **sentiment fusion**, **voice interaction**, and **contextual memory** to deliver accurate and human-like query resolution.

---

## ğŸ“¸ Demo (Coming Soon)

> Screen recording of real-time interaction, including voice input/output, memory-aware follow-up, and context handling.

---

## ğŸŒ Features

* âœ… **Text & Audio Support**: Accepts both text and voice input.
* ğŸ§  **LLM-Powered Conversations**: Uses Azure OpenAIâ€™s GPT-4o via LangChain v3.0.
* ğŸ’¬ **Memory-Aware Chat**: Summarized long-term memory with `ConversationSummaryBufferMemory`.
* ğŸ‘¢ **Sentiment Fusion**: Combines text + voice tone for smarter emotion-aware responses.
* ğŸ¤ **Speech-to-Text**: Uses Whisper for audio transcription.
* ğŸ”Š **Text-to-Speech**: Uses pyttsx3 for audio replies.
* ğŸŒ **Interactive Frontend**: Built with HTML, CSS, JS for real-time voice/text chat.
* ğŸ“† **Local DB Logging**: Saves user queries, bot replies, and sentiments via SQLite.
* ğŸ§  **Pluggable Knowledge Base**: (Planned) Load external documents and FAQs for enhanced answering.
* ğŸ“¡ **FastAPI Backend**: Handles full request lifecycle with audio/text, threading, and structured endpoints.

---

## ğŸ—ï¸ Project Architecture
```mermaid
flowchart TD
    UserInput[User Input: Text or Audio]
    APIEndpoint["FastAPI POST /chat/"]
    Transcription["Transcribe Audio â†’ Text"]
    TextSentiment["Analyze Text Sentiment"]
    AudioSentiment["Analyze Audio Sentiment (if audio)"]
    FuseSentiment["Fuse Text + Audio Sentiments"]
    LLM["Call LLM with Input + Memory + Sentiment Context"]
    LLMResponse["LLM Response (Text)"]
    TTS["Generate Text-to-Speech Audio"]
    DB["Log Conversation in Database"]
    APIResponse["Return JSON response containing text and audio file URL"]
    Frontend["Frontend Displays Text & Plays Audio"]

    UserInput --> APIEndpoint
    APIEndpoint -->|If Audio| Transcription --> TextSentiment
    APIEndpoint -->|If Text| TextSentiment
    APIEndpoint -->|If Audio| AudioSentiment
    TextSentiment --> FuseSentiment
    AudioSentiment --> FuseSentiment
    FuseSentiment --> LLM
    LLM --> LLMResponse
    LLMResponse --> TTS
    LLMResponse --> DB
    TTS --> DB
    DB --> APIResponse
    APIResponse --> Frontend
```

---

## ğŸ§¹ Tech Stack

| Layer       | Technology                               |
| ----------- | ---------------------------------------- |
| ğŸ¯ Backend  | Python, FastAPI                          |
| ğŸ§  AI       | LangChain 3.0, Azure OpenAI GPT-4o       |
| ğŸ’» Memory   | LangChain Summary Buffer                 |
| ğŸ§ª NLP      | VaderSentiment, Whisper, pyAudioAnalysis |
| ğŸ”Š Audio    | pyttsx3, Whisper                         |
| ğŸ“ Database | SQLite                                   |
| ğŸ–¥ Frontend | HTML, CSS, Vanilla JS                    |
| ğŸ“¦ Others   | Python threading, uuid, Jinja2           |

---

## ğŸ“ Directory Structure

```
project-cyfutureai/
â”‚
â”œâ”€â”€ main.py                       # FastAPI backend logic
â”œâ”€â”€ audio_transcriber.py          # Whisper transcriber
â”œâ”€â”€ audio_sentiment.py            # Emotion detection via audio
â”œâ”€â”€ text_sentiment.py             # Vader-based sentiment
â”œâ”€â”€ fusion_logic.py               # Rule-based sentiment fusion
â”œâ”€â”€ llm_chain.py                  # LangChain + Azure GPT-4o interface
â”œâ”€â”€ chat_memory.py                # LLM memory using summary buffer
â”œâ”€â”€ tts_response.py               # Text-to-speech audio output
â”œâ”€â”€ database.py                   # Chat logging into SQLite
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                # Interactive frontend
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ favicon.ico               # For tab icon
â”‚   â”œâ”€â”€ styles.css                # Frontend styling
â”‚   â””â”€â”€ audio/                    # TTS response files
â”‚
â”œâ”€â”€ uploads/                      # Incoming audio files
â”‚
â”œâ”€â”€ chatbot.log                   # All logs
â”œâ”€â”€ conversations.db              # SQLite DB file
â”œâ”€â”€ requirements.txt              # All dependencies
â””â”€â”€ README.md                     # This file
```

---

## âš™ï¸ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/project-cyfutureai.git
cd project-cyfutureai
```

### 2. Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Environment Variables

Set these before running (replace with your actual values):

```bash
export AZURE_OPENAI_API_KEY=your_key
export AZURE_OPENAI_ENDPOINT=your_endpoint
```

On Windows:

```cmd
set AZURE_OPENAI_API_KEY=your_key
set AZURE_OPENAI_ENDPOINT=your_endpoint
```

### 5. Start the App

```bash
uvicorn main:app --reload
```

---

## ğŸš§ To-Do & Upcoming Features

* [ ] ğŸ” **External Knowledge Integration** (via FAISS + LangChain retriever)
* [ ] ğŸ§ Audio Record Cancel/Re-record Feature (frontend UX)
* [ ] ğŸŒ Multilingual Translation Support
* [ ] ğŸ§¾ Advanced Logging with Query Categories
* [ ] â˜ï¸ Docker Deployment Guide
* [ ] ğŸ“ API Documentation with Swagger

---

## ğŸ¤ Contributing

We welcome pull requests, suggestions, and feedback! To contribute:

* Fork the repo
* Create your feature branch (`git checkout -b feature/your-feature`)
* Commit your changes
* Push to your branch
* Open a Pull Request

---

## ğŸ“„ License

This project is under the [MIT License](LICENSE).

---

## ğŸ’¡ Inspiration

Built with the vision of reducing customer support overhead by creating a smart, empathetic, and scalable L1 support bot that understands voice, tone, and intent â€” not just words.

---

## ğŸ“¬ Contact

For collaboration or queries:

* ğŸ“¬ Email: [rupam.ganguly46@gmail.com](mailto:rupam.ganguly46@gmail.com)
* ğŸ§  LinkedIn: [www.linkedin.com/in/rupam-ganguly-88329328b](www.linkedin.com/in/rupam-ganguly-88329328b)

---

> â­ Donâ€™t forget to Star the repo if you find it helpful!
